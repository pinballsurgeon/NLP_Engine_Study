{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LLM Alignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlV3ZMTUKnsMtPfvazLhMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinballsurgeon/NLP_Engine_Study/blob/main/LLM_Alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install"
      ],
      "metadata": {
        "id": "g5u-EKIhWuSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU85Rtm5Wp4U",
        "outputId": "9cf4a3e9-342a-4e3f-f821-e8fb4f08e707"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 6.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "FHs_YYbzWqf-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RZLIOaXhWYA3"
      },
      "outputs": [],
      "source": [
        "# standard dan-dard\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import numpy\n",
        "import pandas\n",
        "import string\n",
        "import seaborn\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow_hub\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins import projector\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        " \n",
        "# universal encoder\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = tensorflow_hub.load(module_url)\n",
        "\n",
        "# set up a logs directory, so Tensorboard knows where to look for files.\n",
        "log_dir='/logs/embedding_projector/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "# LM transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
        "\n",
        "# load tensorboar dextension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download"
      ],
      "metadata": {
        "id": "933E4XA_Xw5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b3\", use_cache=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\")"
      ],
      "metadata": {
        "id": "dIBl-gISXxjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}