{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LLM Alignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq6wSxjDDaVCwSwG8VdgjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinballsurgeon/NLP_Engine_Study/blob/main/LLM_Alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install"
      ],
      "metadata": {
        "id": "g5u-EKIhWuSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install transformers\n",
        "!pip install transformers -q\n",
        "\n",
        "# install openai\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU85Rtm5Wp4U",
        "outputId": "9cf4a3e9-342a-4e3f-f821-e8fb4f08e707"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 6.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "FHs_YYbzWqf-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RZLIOaXhWYA3"
      },
      "outputs": [],
      "source": [
        "# standard dan-dard\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import numpy\n",
        "import pandas\n",
        "import string\n",
        "import seaborn\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow_hub\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins import projector\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        " \n",
        "# universal encoder\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = tensorflow_hub.load(module_url)\n",
        "\n",
        "# set up a logs directory, so Tensorboard knows where to look for files.\n",
        "log_dir='/logs/embedding_projector/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "# LM transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
        "\n",
        "# gpt3 \n",
        "import openai\n",
        "\n",
        "# supply openai api key via file \n",
        "openai.api_key = open('openai_key').read()\n",
        "\n",
        "# load tensorboar dextension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download"
      ],
      "metadata": {
        "id": "933E4XA_Xw5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-1b3\", use_cache=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\")"
      ],
      "metadata": {
        "id": "dIBl-gISXxjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "ZYRlEHOAZ_1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 5. send openai question, receive response\n",
        "def get_openai_response(question):\n",
        "\n",
        "    # format open au request\n",
        "    response = openai.Completion.create(\n",
        "                      engine=\"text-davinci-001\",\n",
        "                      prompt=question,\n",
        "                      temperature=.5,\n",
        "                      max_tokens=250,\n",
        "                      top_p=1,\n",
        "                      frequency_penalty=50,\n",
        "                      presence_penalty=0 )\n",
        "\n",
        "    # parse and process open ai response\n",
        "    response_choices = response[\"choices\"]\n",
        "\n",
        "    # replace blanks\n",
        "    response = response_choices[0][\"text\"].strip('\\n')\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "nx9SUBMSZ9FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_openai_generated_topics(topic, obj, state):\n",
        "  \n",
        "  new_tokens_list = []\n",
        "\n",
        "  responses = []\n",
        "\n",
        "  # retrieve \n",
        "  retrieval = get_openai_response('from the perspetive of a %s resident, list several single word %s related to %s' % ( state , obj , topic ))\n",
        "  # retrieval = get_openai_response('list one word %s related to %s' % (obj , topic))\n",
        "  responses.append(retrieval)\n",
        "\n",
        "  new_tokens = re.split(\"; |, |\\*|\\n\",responses[0].lower())\n",
        "\n",
        "  return new_tokens"
      ],
      "metadata": {
        "id": "ILlyBtILazVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RBwA0bNxazof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IZx76rBVaz2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}